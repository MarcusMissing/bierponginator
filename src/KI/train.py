import numpy as npimport tensorflow as tffrom tensorflow.keras.optimizers import Adamfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateaufrom sklearn.model_selection import train_test_splitfrom KI.smallervggnet import SmallerVGGNetfrom KI import config# Run Tensorboard: tensorboard --logdir=resource/tensorboard in TerminalImage_size = config.image_size_0npz_file_path = 'resource/preprocessed_images_128.npz'X = np.load(npz_file_path)['X']y = np.array(np.load(npz_file_path)['lables'], dtype='int')(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.2, random_state=42)# construct the image generator for data augmentationaug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,                         horizontal_flip=True, fill_mode='nearest')# initialize the model using a sigmoid activation as the final layer# in the network so we can perform multi-label classificationmodel = SmallerVGGNet.build(    width=Image_size[1], height=Image_size[0],    depth=Image_size[2], classes=10,    finalAct='sigmoid')# model = models.MobileNetv2(input_shape=config.image_size_0, k=10)# initialize the optimizer (SGD is sufficient)opt = Adam(lr=config.iteration_learn_rate, decay=config.iteration_learn_rate / config.epochs)model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(    filepath='resource/checkpoints/' + "model_128_1.h5",    save_weights_only=False,    monitor='accuracy',    mode='max',    save_best_only=True)tensorboard_callback = TensorBoard(log_dir='resource/tensorboard', histogram_freq=1)reduce_lr = ReduceLROnPlateau(monitor="binary_crossentropy", factor=0.2, patience=6, min_lr=0.0001)# compile the model using binary cross-entropy rather than# categorical cross-entropy -- this may seem counterintuitive for# multi-label classification, but keep in mind that the goal here# is to treat each output label as an independent Bernoulli# distributionmodel.compile(loss='binary_crossentropy', optimizer=opt,              metrics=['accuracy'])model.fit_generator(    aug.flow(trainX, trainY, batch_size=config.batch_size),    validation_data=(testX, testY),    steps_per_epoch=len(trainX) // config.batch_size,    epochs=config.epochs, verbose=1, callbacks=[model_checkpoint_callback, tensorboard_callback])# model.save('../resource/model.h5')